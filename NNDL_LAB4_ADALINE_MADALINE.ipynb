{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvIbKwF04F8cMLg74/aDFD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeepss2020/Neural_Network-DL/blob/main/NNDL_LAB4_ADALINE_MADALINE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the module numpy\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "GkDCH96Iud6r"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***ADALINE Network***"
      ],
      "metadata": {
        "id": "MMdr0jpASs_B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWTPDFXjsQ4s",
        "outputId": "46d31882-a6a4-488b-9b4f-396bfec547f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orginial Matrix  [[ 1  1]\n",
            " [ 1 -1]\n",
            " [-1  1]\n",
            " [-1 -1]] [ 1  1  1 -1]\n",
            "epoch : 1\n",
            "error = 0.7\n",
            "error = 0.8300000000000001\n",
            "error = 0.913\n",
            "error = -1.0043\n",
            "sum of squared error =  0.7552718725 \n",
            "\n",
            "\n",
            "epoch : 2\n",
            "error = 0.21527000000000007\n",
            "error = 0.751203\n",
            "error = 0.7931233000000001\n",
            "error = -0.83591563\n",
            "sum of squared error =  0.4846116573975468 \n",
            "\n",
            "\n",
            "epoch : 3\n",
            "error = -0.08733519300000014\n",
            "error = 0.6974795122999999\n",
            "error = 0.71725934353\n",
            "error = -0.7353483458829999\n",
            "sum of squared error =  0.3873258154221359 \n",
            "\n",
            "\n",
            "epoch : 4\n",
            "error = -0.2761433552713002\n",
            "error = 0.66111076307843\n",
            "error = 0.669341786894273\n",
            "error = -0.6754034326425002\n",
            "sum of squared error =  0.3543777045566816 \n",
            "\n",
            "\n",
            "epoch : 5\n",
            "error = -0.39388594695143064\n",
            "error = 0.6366406508037212\n",
            "error = 0.6391322538657562\n",
            "error = -0.639748288011841\n",
            "sum of squared error =  0.34455634185180345 \n",
            "\n",
            "\n",
            "epoch : 6\n",
            "error = -0.4672722821341333\n",
            "error = 0.6202637379637779\n",
            "error = 0.6201210085170047\n",
            "error = -0.6185895044697803\n",
            "sum of squared error =  0.34256838263198863 \n",
            "\n",
            "\n",
            "epoch : 7\n",
            "error = -0.5129880225889496\n",
            "error = 0.609354470132218\n",
            "error = 0.608177905680998\n",
            "error = -0.6060646929690626\n",
            "sum of squared error =  0.3429160896530115 \n",
            "\n",
            "\n",
            "epoch : 8\n",
            "error = -0.5414513226904927\n",
            "error = 0.602117521226608\n",
            "error = 0.6006878876653149\n",
            "error = -0.5986709582365854\n",
            "sum of squared error =  0.343736974708772 \n",
            "\n",
            "\n",
            "epoch : 9\n",
            "error = -0.5591635625961957\n",
            "error = 0.597334505708435\n",
            "error = 0.5959984240198419\n",
            "error = -0.5943193199980572\n",
            "sum of squared error =  0.3444754942505746 \n",
            "\n",
            "\n",
            "epoch : 10\n",
            "error = -0.5701797187899702\n",
            "error = 0.5941839002766915\n",
            "error = 0.5930671907203613\n",
            "error = -0.5917666049773423\n",
            "sum of squared error =  0.3450189566356955 \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "features = np.array(\n",
        "\t[\n",
        "\t\t[1, 1],\n",
        "\t\t[1, -1],\n",
        "\t\t[-1, 1],\n",
        "\t\t[-1, -1]\n",
        "\t])\n",
        "\n",
        "labels = np.array([1, 1, 1, -1])\n",
        "print(\"Orginial Matrix \",features, labels)\n",
        "\n",
        "# initialise weights, bias , learning rate, epoch\n",
        "weight = [0.1, 0.1]\n",
        "bias = 0.1\n",
        "learning_rate = 0.1\n",
        "epoch = 10\n",
        "check_num = [10]\n",
        "\n",
        "\n",
        "for i in range(epoch):\n",
        "    # print(check_num)\n",
        "    print(\"epoch :\", i+1)\n",
        "    # variable to check if there is no change in previous weight and present calculated weight\n",
        "    sum_squared_error = 0.0\n",
        "    \n",
        "\n",
        "    # for each of the possible input given in the features\n",
        "    for j in range(features.shape[0]):\n",
        "      actual = labels[j]\n",
        "      x1 = features[j][0]\n",
        "      x2 = features[j][1]\n",
        "      unit = (x1 * weight[0]) + (x2 * weight[1]) + bias\n",
        "      \n",
        "\n",
        "      # error is computed so as to update the weights\n",
        "      error = actual - unit\n",
        "      print(\"error =\", error)\n",
        "\n",
        "      # summation of squared error is calculated\n",
        "      sum_squared_error += error * error\n",
        "      \n",
        "      \n",
        "      \n",
        "\n",
        "      # updation of weights\n",
        "\n",
        "      weight[0] += learning_rate * error * x1\n",
        "      weight[1] += learning_rate * error * x2\n",
        "\n",
        "      # updation of bias\n",
        "      bias += learning_rate * error\n",
        "      \n",
        "\n",
        "\n",
        "    print(\"sum of squared error = \", sum_squared_error/4, \"\\n\\n\")\n",
        "   \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***MADALINE NETWORK***"
      ],
      "metadata": {
        "id": "N2u-fDiOTjRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.array(\n",
        "\t[\n",
        "\t\t[1, 1],\n",
        "\t\t[1, -1],\n",
        "\t\t[-1, 1],\n",
        "\t\t[-1, -1]\n",
        "\t])\n",
        "\n",
        "labels = np.array([-1, 1, 1, -1])\n",
        "print(\"Orginial Matrix \",features, labels ,\"\\n\")\n",
        "\n",
        "# initialise weights, bias , learning rate, epoch\n",
        "weight = [0.3,0.2,0.1,0.3]\n",
        "bias = [0.2,0.1,0.3]\n",
        "v = [0.3,0.3]\n",
        "\n",
        "learning_rate = 0.1\n",
        "epoch = 5\n",
        "\n",
        "for j in range(epoch):\n",
        "  # print(check_num)\n",
        "  print(\"======================================================================\")\n",
        "  print(\"EPOCH:\", j+1)\n",
        "  # variable to check if there is no change in previous weight and present calculated weight\n",
        "  sum_squared_error = 0.0\n",
        "  avrg_error =[]\n",
        " \n",
        "\n",
        "  for i in range (features.shape[0]):\n",
        "    lst_z =[]\n",
        "    x1 = features[i][0]\n",
        "    x2 = features[i][1]\n",
        "    Z1 = (x1 * weight[0]) + (x2 * weight[2]) + bias[0]\n",
        "    lst_z.append(Z1)\n",
        "    Z2 = (x1 * weight[1]) + (x2 * weight[3]) + bias[1]\n",
        "    lst_z.append(Z2)\n",
        "    print(\"x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]: \", x1,x2,weight[0],weight[1],weight[2],weight[3],bias[0],bias[1])\n",
        "    # print(f\"Z1 : {Z1}, Z2 : {Z2}\")\n",
        "    print(lst_z)\n",
        "\n",
        "    if(Z1>=0):\n",
        "      f_z1 = 1\n",
        "    elif(Z1 <0):\n",
        "      f_z1 = -1\n",
        "    if(Z2>=0):\n",
        "      f_z2 = 1\n",
        "    elif(Z2<0):\n",
        "      f_z2 = -1\n",
        "    # print(\"fz1  and f_z2 : \", f_z1,f_z2)\n",
        "\n",
        "    y = bias[2] + f_z1*v[0] + f_z2* v[1]\n",
        "    # print(y)\n",
        "    \n",
        "    y2 = bias[2] + Z1*v[0] + Z2 *v[1]\n",
        "\n",
        "    yin = f_z1 * v [0] + f_z2 * v[1] + bias[2]\n",
        "    print(f\" Yin : {yin}\")\n",
        "\n",
        "    if(yin>=0):\n",
        "      f_y = 1\n",
        "    elif(yin <0):\n",
        "      f_y = -1\n",
        "\n",
        "    error1 = labels[i] - Z1\n",
        "    error2 = labels[i] - Z2\n",
        "    if labels[i] < 0:\n",
        "      if f_z1 == 1 and f_z2 == 1:\n",
        "        weight[0] += learning_rate * error1 * x1\n",
        "        weight[1] += learning_rate * error2 * x1\n",
        "        weight[2] += learning_rate * error1 * x2\n",
        "        weight[3] += learning_rate * error2 * x2\n",
        "        bias[0] += learning_rate * error1\n",
        "        bias[1] += learning_rate * error2\n",
        "      elif f_z1 == 1 and f_z2 == -1:\n",
        "        weight[0] += learning_rate * error1 * x1\n",
        "        weight[2] += learning_rate * error1 * x2\n",
        "        bias[0] += learning_rate * error1\n",
        "      elif f_z2 == 1 and f_z1 == -1:\n",
        "        weight[1] += learning_rate * error2 * x1\n",
        "        weight[3] += learning_rate * error2 * x2\n",
        "        bias[1] += learning_rate * error2\n",
        "\n",
        "\n",
        "    elif labels[i] > 0:\n",
        "      c=min(lst_z, key=abs)\n",
        "      if c == Z2:     #check2 is close to zero\n",
        "        weight[1] += learning_rate * error2 * x1\n",
        "        weight[3] += learning_rate * error2 * x2\n",
        "        bias[1] += learning_rate * error2\n",
        "\n",
        "      elif c == Z1:\n",
        "        weight[0] += learning_rate * error1 * x1\n",
        "        weight[2] += learning_rate * error1 * x2\n",
        "        bias[0] += learning_rate * error1\n",
        "# print('%.4f' % s)\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    # if f_y != labels[i]:\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxtJVijkTqmH",
        "outputId": "0554dbfb-39bf-464f-f3fd-1462bb7b6f41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orginial Matrix  [[ 1  1]\n",
            " [ 1 -1]\n",
            " [-1  1]\n",
            " [-1 -1]] [-1  1  1 -1] \n",
            "\n",
            "======================================================================\n",
            "EPOCH: 1\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  1 1 0.3 0.2 0.1 0.3 0.2 0.1\n",
            "[0.6000000000000001, 0.6]\n",
            " Yin : 0.8999999999999999\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  1 -1 0.13999999999999996 0.03999999999999998 -0.060000000000000026 0.13999999999999996 0.03999999999999998 -0.060000000000000026\n",
            "[0.23999999999999996, -0.16]\n",
            " Yin : 0.3\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  -1 1 0.13999999999999996 0.15599999999999997 -0.060000000000000026 0.023999999999999966 0.03999999999999998 0.055999999999999966\n",
            "[-0.16, -0.07600000000000004]\n",
            " Yin : -0.3\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  -1 -1 0.13999999999999996 0.04839999999999996 -0.060000000000000026 0.1316 0.03999999999999998 0.16359999999999997\n",
            "[-0.03999999999999995, -0.01639999999999997]\n",
            " Yin : -0.3\n",
            "======================================================================\n",
            "EPOCH: 2\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  1 1 0.13999999999999996 0.04839999999999996 -0.060000000000000026 0.1316 0.03999999999999998 0.16359999999999997\n",
            "[0.11999999999999991, 0.3435999999999999]\n",
            " Yin : 0.8999999999999999\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  1 -1 0.02799999999999997 -0.08596000000000005 -0.17200000000000001 -0.0027600000000000124 -0.07200000000000001 0.02923999999999996\n",
            "[0.12799999999999997, -0.05396000000000008]\n",
            " Yin : 0.3\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  -1 1 0.02799999999999997 0.019435999999999953 -0.17200000000000001 -0.10815600000000002 -0.07200000000000001 0.13463599999999998\n",
            "[-0.272, 0.007043999999999995]\n",
            " Yin : 0.3\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  -1 -1 0.02799999999999997 -0.07985960000000004 -0.17200000000000001 -0.008860400000000018 -0.07200000000000001 0.23393159999999996\n",
            "[0.07200000000000004, 0.32265160000000004]\n",
            " Yin : 0.8999999999999999\n",
            "======================================================================\n",
            "EPOCH: 3\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  1 1 0.1352 0.05240555999999995 -0.0648 0.12340475999999997 -0.17920000000000003 0.10166643999999997\n",
            "[-0.10880000000000004, 0.2774767599999999]\n",
            " Yin : 0.3\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  1 -1 0.1352 -0.07534211600000006 -0.0648 -0.00434291600000003 -0.17920000000000003 -0.026081236000000035\n",
            "[0.020799999999999957, -0.09708043600000006]\n",
            " Yin : 0.3\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  -1 1 0.23312 -0.07534211600000006 -0.16272 -0.00434291600000003 -0.08128000000000002 -0.026081236000000035\n",
            "[-0.47712, 0.04491796399999999]\n",
            " Yin : 0.3\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  -1 -1 0.23312 -0.17085031960000008 -0.16272 0.09116528759999998 -0.08128000000000002 0.06942696759999997\n",
            "[-0.15168, 0.14911199960000007]\n",
            " Yin : 0.3\n",
            "======================================================================\n",
            "EPOCH: 4\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  1 1 0.23312 -0.05593911964000006 -0.16272 0.20607648756 -0.08128000000000002 -0.04548423236000004\n",
            "[-0.010880000000000029, 0.10465313555999989]\n",
            " Yin : 0.3\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  1 -1 0.23312 -0.16640443319600007 -0.16272 0.09561117400399999 -0.08128000000000002 -0.15594954591600005\n",
            "[0.31455999999999995, -0.41796515311600013]\n",
            " Yin : 0.3\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  -1 1 0.301664 -0.16640443319600007 -0.23126400000000003 0.09561117400399999 -0.012736000000000011 -0.15594954591600005\n",
            "[-0.545664, 0.10606606128400001]\n",
            " Yin : 0.3\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  -1 -1 0.301664 -0.25579782706760007 -0.23126400000000003 0.1850045678756 -0.012736000000000011 -0.06655615204440005\n",
            "[-0.08313599999999997, 0.004237107147600033]\n",
            " Yin : 0.3\n",
            "======================================================================\n",
            "EPOCH: 5\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  1 1 0.301664 -0.15537411635284007 -0.23126400000000003 0.28542827859036 -0.012736000000000011 -0.16697986275916005\n",
            "[0.05766399999999995, -0.0369257005216401]\n",
            " Yin : 0.3\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  1 -1 0.1958976 -0.15537411635284007 -0.3370304 0.28542827859036 -0.11850240000000001 -0.16697986275916005\n",
            "[0.41442560000000006, -0.6077822577023602]\n",
            " Yin : 0.3\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  -1 1 0.25445504 -0.15537411635284007 -0.39558784 0.28542827859036 -0.05994496000000001 -0.16697986275916005\n",
            "[-0.70998784, 0.27382253218404]\n",
            " Yin : 0.3\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] , b[0] , b[1]:  -1 -1 0.25445504 -0.2279918631344361 -0.39558784 0.358046025371956 -0.05994496000000001 -0.09436211597756404\n",
            "[0.08118783999999998, -0.22441627821508398]\n",
            " Yin : 0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yCYrobEsTpfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO MADALINE Rough By not considering the conditions\n",
        "Just to check"
      ],
      "metadata": {
        "id": "9V6VzvKoT1cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.array(\n",
        "\t[\n",
        "\t\t[1, 1],\n",
        "\t\t[1, -1],\n",
        "\t\t[-1, 1],\n",
        "\t\t[-1, -1]\n",
        "\t])\n",
        "\n",
        "labels = np.array([-1, 1, 1, -1])\n",
        "print(\"Orginial Matrix \",features, labels ,\"\\n\")\n",
        "\n",
        "# initialise weights, bias , learning rate, epoch\n",
        "weight = [0.05,0.1,0.2,0.2]\n",
        "bias = [0.3,0.15,0.5]\n",
        "v = [0.5,0.5]\n",
        "\n",
        "learning_rate = 0.5\n",
        "epoch = 5\n",
        "\n",
        "for j in range(epoch):\n",
        "  # print(check_num)\n",
        "  print(\"======================================================================\")\n",
        "  print(\"EPOCH:\", j+1)\n",
        "  # variable to check if there is no change in previous weight and present calculated weight\n",
        "  sum_squared_error = 0.0\n",
        "  avrg_error =[]\n",
        "\n",
        "  for i in range (features.shape[0]):\n",
        "    x1 = features[i][0]\n",
        "    x2 = features[i][1]\n",
        "    Z1 = (x1 * weight[0]) + (x2 * weight[2]) + bias[0]\n",
        "    Z2 = (x1 * weight[1]) + (x2 * weight[3]) + bias[1]\n",
        "    # print(\"x1, x2,  w[0] , w[1] , w[2] , w[3] : \", x1,x2,weight[0],weight[1],weight[2],weight[3])\n",
        "    print(f\"Z1 : {Z1}, Z2 : {Z2}\")\n",
        "\n",
        "    if(Z1>=0):\n",
        "      f_z1 = 1\n",
        "    elif(Z1 <0):\n",
        "      f_z1 = -1\n",
        "    if(Z2>=0):\n",
        "      f_z2 = 1\n",
        "    elif(Z2<0):\n",
        "      f_z2 = -1\n",
        "    # print(\"fz1  and f_z2 : \", f_z1,f_z2)\n",
        "\n",
        "    y = bias[2] + f_z1*v[0] + f_z2* v[1]\n",
        "    # print(y)\n",
        "    \n",
        "    y2 = bias[2] + Z1*v[0] + Z2 *v[1]\n",
        "    T_Error = labels[i] - y2                  \n",
        "    print(\"Total Error is : \" , T_Error)\n",
        "    sum_squared_error += T_Error * T_Error\n",
        "    av=sum_squared_error/4\n",
        "    print(\"SQ error : \" ,av)\n",
        "    avrg_error.append(av)\n",
        "\n",
        "    error1 = labels[i] - Z1\n",
        "    # print(\"error1: \", error1)\n",
        "    error2 = labels[i] - Z2\n",
        "    # print(\"error2: \", error2,\"\\n\\n\")\n",
        "\n",
        "\n",
        "    weight[0] += learning_rate * error1 * x1\n",
        "    weight[1] += learning_rate * error2 * x1\n",
        "    weight[2] += learning_rate * error1 * x2\n",
        "    weight[3] += learning_rate * error2 * x2\n",
        "\n",
        "\n",
        "  # updation of bias\n",
        "    bias[0] += learning_rate * error1\n",
        "    bias[1] += learning_rate * error2\n",
        "\n",
        "  sum_error = 0\n",
        "  # print(avrg_error)\n",
        "  for av_i in (avrg_error):\n",
        "    # print(\"av_i\" , av_i)\n",
        "    sum_error += av_i\n",
        "  s = sum_error/4\n",
        "  print(\"Average Error:\",s,\"\\n\\n\")\n",
        "\n",
        "# print('%.4f' % s)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFyY3tHp1rso",
        "outputId": "9d997a18-8266-4191-d3ec-249a1d356ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orginial Matrix  [[ 1  1]\n",
            " [ 1 -1]\n",
            " [-1  1]\n",
            " [-1 -1]] [-1  1  1 -1] \n",
            "\n",
            "======================================================================\n",
            "EPOCH: 1\n",
            "Z1 : 0.55, Z2 : 0.45000000000000007\n",
            "Total Error is :  -2.0\n",
            "SQ error :  1.0\n",
            "Z1 : -0.625, Z2 : -0.675\n",
            "Total Error is :  1.15\n",
            "SQ error :  1.330625\n",
            "Z1 : -1.1375000000000002, Z2 : -1.3125000000000002\n",
            "Total Error is :  1.725\n",
            "SQ error :  2.07453125\n",
            "Z1 : 2.70625, Z2 : 2.5687500000000005\n",
            "Total Error is :  -4.1375\n",
            "SQ error :  6.3542578125\n",
            "Average Error: 2.689853515625 \n",
            "\n",
            "\n",
            "======================================================================\n",
            "EPOCH: 2\n",
            "Z1 : 1.959375, Z2 : 2.0531249999999996\n",
            "Total Error is :  -3.5062499999999996\n",
            "SQ error :  3.0734472656249996\n",
            "Z1 : -2.5890625000000003, Z2 : -2.6296875\n",
            "Total Error is :  3.109375\n",
            "SQ error :  5.490500488281249\n",
            "Z1 : -3.05859375, Z2 : -2.96953125\n",
            "Total Error is :  3.5140625\n",
            "SQ error :  8.577659301757812\n",
            "Z1 : 2.4503906250000007, Z2 : 2.5417968749999993\n",
            "Total Error is :  -3.99609375\n",
            "SQ error :  12.569850616455078\n",
            "Average Error: 7.427864418029785 \n",
            "\n",
            "\n",
            "======================================================================\n",
            "EPOCH: 3\n",
            "Z1 : 3.0693359375, Z2 : 3.0439453125\n",
            "Total Error is :  -4.556640625\n",
            "SQ error :  5.190743446350098\n",
            "Z1 : -2.99462890625, Z2 : -2.9627929687499996\n",
            "Total Error is :  3.4787109375\n",
            "SQ error :  8.216100893020629\n",
            "Z1 : -2.7278808593750004, Z2 : -2.789501953125\n",
            "Total Error is :  3.25869140625\n",
            "SQ error :  10.87086831331253\n",
            "Z1 : 3.1707275390625, Z2 : 3.1272216796875005\n",
            "Total Error is :  -4.648974609375\n",
            "SQ error :  16.27410954296589\n",
            "Average Error: 10.137955548912286 \n",
            "\n",
            "\n",
            "======================================================================\n",
            "EPOCH: 4\n",
            "Z1 : 2.91195068359375, Z2 : 2.91778564453125\n",
            "Total Error is :  -4.4148681640625\n",
            "SQ error :  4.872765226513147\n",
            "Z1 : -2.9079650878906254, Z2 : -2.9358581542968754\n",
            "Total Error is :  3.4219116210937504\n",
            "SQ error :  7.800135012157262\n",
            "Z1 : -3.1313812255859377, Z2 : -3.095681762695313\n",
            "Total Error is :  3.6135314941406254\n",
            "SQ error :  11.064537476943807\n",
            "Z1 : 2.8902847290039064, Z2 : 2.9110519409179685\n",
            "Total Error is :  -4.400668334960938\n",
            "SQ error :  15.906007925525774\n",
            "Average Error: 9.910861410284998 \n",
            "\n",
            "\n",
            "======================================================================\n",
            "EPOCH: 5\n",
            "Z1 : 3.008840179443359, Z2 : 3.0124031066894537\n",
            "Total Error is :  -4.510621643066406\n",
            "SQ error :  5.086426901724771\n",
            "Z1 : -3.061270523071289, Z2 : -3.04163932800293\n",
            "Total Error is :  3.5514549255371097\n",
            "SQ error :  8.23963492375522\n",
            "Z1 : -2.9145071029663083, Z2 : -2.934706306457519\n",
            "Total Error is :  3.4246067047119135\n",
            "SQ error :  11.171617694244668\n",
            "Z1 : 3.0471665382385256, Z2 : 3.038848400115967\n",
            "Total Error is :  -4.543007469177246\n",
            "SQ error :  16.33134691049473\n",
            "Average Error: 10.207256607554847 \n",
            "\n",
            "\n",
            "10.2073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MADALINE Check"
      ],
      "metadata": {
        "id": "h4Sek1yESkAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# features = np.array(\n",
        "# \t[\n",
        "# \t\t[1, 1],\n",
        "# \t\t[1, -1],\n",
        "# \t\t[-1, 1],\n",
        "# \t\t[-1, -1]\n",
        "# \t])\n",
        "\n",
        "# labels = np.array([-1, 1, 1, -1])\n",
        "# print(\"Orginial Matrix \",features, labels)\n",
        "\n",
        "# # initialise weights, bias , learning rate, epoch\n",
        "# weight = [0.05,0.1,0.2,0.2]\n",
        "# bias = [0.3,0.15,0.5]\n",
        "# v = [0.5,0.5]\n",
        "\n",
        "# learning_rate = 0.5\n",
        "# epoch = 5\n",
        "\n",
        "\n",
        "# for i in range (features.shape[0]):\n",
        "#   x1 = features[i][0]\n",
        "#   x2 = features[i][1]\n",
        "#   Z1 = (x1 * weight[0]) + (x2 * weight[2]) + bias[0]\n",
        "#   Z2 = (x1 * weight[1]) + (x2 * weight[3]) + bias[1]\n",
        "#   print(\"x1, x2,  w[0] , w[1] , w[2] , w[3] : \", x1,x2,weight[0],weight[1],weight[2],weight[3])\n",
        "#   print(Z1,Z2)\n",
        "\n",
        "#   if(Z1>=0):\n",
        "#     f_z1 = 1\n",
        "#   elif(Z1 <0):\n",
        "#     f_z1 = -1\n",
        "#   if(Z2>=0):\n",
        "#     f_z2 = 1\n",
        "#   elif(Z2<0):\n",
        "#     f_z2 = -1\n",
        "#   print(\"fz1  and f_z2 : \", f_z1,f_z2)\n",
        "\n",
        "#   y = bias[2] + f_z1*v[0] + f_z2* v[1]\n",
        "#   print(y)\n",
        "        \n",
        "#   T_Error = labels[i] - y                   #need to change the value of label [0] later\n",
        "#   print(\"Error is : \" , T_Error)\n",
        "\n",
        "#   error1 = labels[i] - Z1\n",
        "#   print(\"error1: \", error1)\n",
        "#   error2 = labels[i] - Z2\n",
        "#   print(\"error2: \", error2,\"\\n\\n\")\n",
        "\n",
        "\n",
        "#   weight[0] += learning_rate * error1 * x1\n",
        "#   weight[1] += learning_rate * error2 * x1\n",
        "#   weight[2] += learning_rate * error1 * x2\n",
        "#   weight[3] += learning_rate * error2 * x2\n",
        "\n",
        "\n",
        "#  # updation of bias\n",
        "#   bias[0] += learning_rate * error1\n",
        "#   bias[1] += learning_rate * error2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TP83-odJ9TGV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROUGH\n",
        "for adaline"
      ],
      "metadata": {
        "id": "LtI1tv62fD1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.array(\n",
        "\t[\n",
        "\t\t[-1, -1],\n",
        "\t\t[-1, 1],\n",
        "\t\t[1, -1],\n",
        "\t\t[1, 1]\n",
        "\t])\n",
        "\n",
        "labels = np.array([-1, -1, -1, 1])\n",
        "print(\"Orginial Matrix \",features, labels)\n",
        "\n",
        "# initialise weights, bias , learning rate, epoch\n",
        "weight = [0.3, 0.3]\n",
        "bias = 0.1\n",
        "learning_rate = 0.5\n",
        "epoch = 3\n",
        "\n",
        "\n",
        "for i in range(epoch):\n",
        "    # print(check_num)\n",
        "    print(\"epoch :\", i+1)\n",
        "    # variable to check if there is no change in previous weight and present calculated weight\n",
        "    sum_squared_error = 0.0\n",
        "    \n",
        "\n",
        "    # for each of the possible input given in the features\n",
        "    for j in range(features.shape[0]):\n",
        "      actual = labels[j]\n",
        "      x1 = features[j][0]\n",
        "      x2 = features[j][1]\n",
        "      unit = (x1 * weight[0]) + (x2 * weight[1]) + bias\n",
        "      \n",
        "\n",
        "      # error is computed so as to update the weights\n",
        "      error = actual - unit\n",
        "      print(\"error =\", error)\n",
        "\n",
        "      # summation of squared error is calculated\n",
        "      sum_squared_error += error * error\n",
        "      \n",
        "      \n",
        "      \n",
        "\n",
        "      # updation of weights\n",
        "\n",
        "      weight[0] += learning_rate * error * x1\n",
        "      weight[1] += learning_rate * error * x2\n",
        "      print(f\"w1 : {weight[0]}  w2 : {weight[1]}\")\n",
        "      # updation of bias\n",
        "      bias += learning_rate * error\n",
        "      print(\"bias : \", bias,\"\\n\\n\")\n",
        "      \n",
        "\n",
        "\n",
        "    print(\"sum of squared error = \", sum_squared_error/4, \"\\n\\n\")\n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DB5kNHcfDPn",
        "outputId": "abd488d6-22f6-4d48-b74c-b606154ea60b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orginial Matrix  [[-1 -1]\n",
            " [-1  1]\n",
            " [ 1 -1]\n",
            " [ 1  1]] [-1 -1 -1  1]\n",
            "epoch : 1\n",
            "error = -0.5\n",
            "w1 : 0.55  w2 : 0.55\n",
            "bias :  -0.15 \n",
            "\n",
            "\n",
            "error = -0.85\n",
            "w1 : 0.9750000000000001  w2 : 0.12500000000000006\n",
            "bias :  -0.575 \n",
            "\n",
            "\n",
            "error = -1.2750000000000001\n",
            "w1 : 0.3375  w2 : 0.7625000000000002\n",
            "bias :  -1.2125 \n",
            "\n",
            "\n",
            "error = 1.1124999999999998\n",
            "w1 : 0.8937499999999999  w2 : 1.31875\n",
            "bias :  -0.65625 \n",
            "\n",
            "\n",
            "sum of squared error =  0.9589453125 \n",
            "\n",
            "\n",
            "epoch : 2\n",
            "error = 1.86875\n",
            "w1 : -0.04062500000000002  w2 : 0.38437500000000013\n",
            "bias :  0.27812499999999996 \n",
            "\n",
            "\n",
            "error = -1.703125\n",
            "w1 : 0.8109375  w2 : -0.46718749999999987\n",
            "bias :  -0.5734375 \n",
            "\n",
            "\n",
            "error = -1.7046874999999997\n",
            "w1 : -0.04140624999999987  w2 : 0.38515625\n",
            "bias :  -1.42578125 \n",
            "\n",
            "\n",
            "error = 2.08203125\n",
            "w1 : 0.9996093750000001  w2 : 1.426171875\n",
            "bias :  -0.384765625 \n",
            "\n",
            "\n",
            "sum of squared error =  3.4084187316894528 \n",
            "\n",
            "\n",
            "epoch : 3\n",
            "error = 1.810546875\n",
            "w1 : 0.09433593750000013  w2 : 0.5208984375000001\n",
            "bias :  0.5205078125 \n",
            "\n",
            "\n",
            "error = -1.9470703125\n",
            "w1 : 1.06787109375  w2 : -0.4526367187499999\n",
            "bias :  -0.45302734375 \n",
            "\n",
            "\n",
            "error = -2.06748046875\n",
            "w1 : 0.034130859375000044  w2 : 0.5811035156250001\n",
            "bias :  -1.4867675781249998 \n",
            "\n",
            "\n",
            "error = 1.8715332031249998\n",
            "w1 : 0.9698974609375  w2 : 1.5168701171875\n",
            "bias :  -0.5510009765624999 \n",
            "\n",
            "\n",
            "sum of squared error =  3.711568701863288 \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "riBNdK3UfT9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # T_Error = labels[i] - y2                  \n",
        "    # print(\"Total Error is : \" , T_Error)\n",
        "    # sum_squared_error += T_Error * T_Error\n",
        "    # av=sum_squared_error/4\n",
        "    # print(\"SQ error : \" ,av)\n",
        "    # avrg_error.append(av)\n",
        "\n",
        "    # error1 = labels[i] - Z1\n",
        "    # # print(\"error1: \", error1)\n",
        "    # error2 = labels[i] - Z2\n",
        "    # # print(\"error2: \", error2,\"\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "  # sum_error = 0\n",
        "  # # print(avrg_error)\n",
        "  # for av_i in (avrg_error):\n",
        "  #   # print(\"av_i\" , av_i)\n",
        "  #   sum_error += av_i\n",
        "  # s = sum_error/4\n",
        "  # print(\"Average Error:\",s,\"\\n\\n\")"
      ],
      "metadata": {
        "id": "LQPmHAbznG4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [37,2,1,-1,-8]\n",
        "min(lst, key=abs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-5wKB5DrvAb",
        "outputId": "8bc090a3-4402-4316-86dd-639970bb6da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oABWwpZ5sIH_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}