{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7Tx6AfqVW6T8jBjVudrVe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeepss2020/Neural_Network-DL/blob/main/2147130_NN_task2(and_or_xor).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing Python library\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "q1kAVKEN0Tow"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define Unit Step Function\n",
        "def actual_result(v):\n",
        "    if v > 1:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "  \n",
        "# design Perceptron Model\n",
        "actual=[]\n",
        "def perceptronModel(x, w, b):\n",
        "    v = np.dot(w, x) + b\n",
        "    y = actual_result(v)\n",
        "    print(v)\n",
        "    actual.append(v)\n",
        "    return y\n",
        "  \n",
        "# AND Logic Function\n",
        "# w1 = 1.5, w2 = 0.5, b = -0.5\n",
        "def AND_logicFunction(x):\n",
        "    w = np.array([1.5, 0.5])\n",
        "    b = -0.5\n",
        "    return perceptronModel(x, w, b)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6F9ALqtRtrMg"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OR Logic Function\n",
        "# w1 = 1.5, w2 = 0.5, b = -0.5\n",
        "def OR_logicFunction(x):\n",
        "    w2 = np.array([1.5, 0.5])\n",
        "    b2 = -0.5\n",
        "    return perceptronModel2(x, w2, b2)\n",
        "\n",
        "\n",
        "# design Perceptron Model\n",
        "actual2=[]\n",
        "def perceptronModel2(x, w2, b2):\n",
        "    v2 = np.dot(w2, x) + b2\n",
        "    y2 = actual_result2(v2)\n",
        "    print(v2)\n",
        "    actual2.append(v2)\n",
        "    return y2\n",
        "\n",
        "# define Unit Step Function\n",
        "def actual_result2(v2):\n",
        "    if v2 >= 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "O7seU3ahx2eQ"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XOR Logic Function\n",
        "# with AND, OR and NOT  \n",
        "# function calls in sequence\n",
        "def XOR_logicFunction(x):\n",
        "    y1xor = AND_logicFunction(x)\n",
        "    y2xor= OR_logicFunction(x)\n",
        "    y3xor = NOT_logicFunction(y1xor)\n",
        "    final_x = np.array([y2xor, y3xor])\n",
        "    finalOutput = AND_logicFunction(final_x)\n",
        "    return finalOutput\n",
        "\n",
        "actual3=[]\n",
        "def perceptronModel3(x, w3xor, b3xor):\n",
        "    v3xor = np.dot(w3xor, x) + b3xor\n",
        "    y3xor = actual_result3(v3xor)\n",
        "    # print(v3xor)\n",
        "    return y3xor\n",
        "\n",
        "# define Unit Step Function\n",
        "def actual_result3(v3xor):\n",
        "    if v3xor >= 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# NOT Logic Function\n",
        "# wNOT = 1.5, bNOT = -0.5\n",
        "def NOT_logicFunction(x):\n",
        "    wNOT = 1.5\n",
        "    bNOT = -0.5\n",
        "    return perceptronModel3(x, wNOT, bNOT)\n",
        "  \n",
        "# AND Logic Function\n",
        "# here w1 = wAND1 = 1.5, \n",
        "# w2 = wAND2 = 0.5, bAND = -0.5\n",
        "def AND_logicFunction(x):\n",
        "    w3 = np.array([1.5, 0.5])\n",
        "    bAND = -0.5\n",
        "    return perceptronModel3(x, w3, bAND)\n",
        "  \n",
        "# OR Logic Function\n",
        "# w1 = 1.5, w2 = 0.5, bOR = -0.5\n",
        "def OR_logicFunction(x):\n",
        "    w3 = np.array([1.5, 0.5])\n",
        "    bOR = -0.5\n",
        "    return perceptronModel3(x, w3, bOR)\n",
        "  \n"
      ],
      "metadata": {
        "id": "Mnx3SZgR1vHg"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO Different Xor Function\n",
        "\n",
        "def XOR_logicFunction2(x):\n",
        "    y1xor2 = AND_logicFunction2(x)\n",
        "    y2xor2= OR_logicFunction2(x)\n",
        "    y3xor2 = NOT_logicFunction2(y1xor2)\n",
        "    final_x2 = np.array([y2xor2, y3xor2])\n",
        "    finalOutput2 = AND_logicFunction2(final_x2)\n",
        "    return finalOutput2\n",
        "\n",
        "actual3_2=[]\n",
        "def perceptronModel3_2(x, w3xor2, b3xor2):\n",
        "    v3xor2 = np.dot(w3xor2, x) + b3xor2\n",
        "    y3xor2 = actual_result32(v3xor2)\n",
        "    # print(v3xor)\n",
        "    # actual3_2.append(v3xor2)\n",
        "    return y3xor2\n",
        "\n",
        "# define Unit Step Function\n",
        "def actual_result32(v3xor2):\n",
        "    if v3xor2 >= 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# NOT Logic Function\n",
        "# wNOT = -1, bNOT = 0.5\n",
        "def NOT_logicFunction2(x):\n",
        "    wNOT2 = -1\n",
        "    bNOT2= 0.5\n",
        "    return perceptronModel3_2(x, wNOT2, bNOT2)\n",
        "  \n",
        "# AND Logic Function\n",
        "# here w1 = wAND1 = 1, \n",
        "# w2 = wAND2 = 1, bAND = -1.5\n",
        "def AND_logicFunction2(x):\n",
        "    w32 = np.array([1, 1])\n",
        "    bAND2 = -1.5\n",
        "    return perceptronModel3_2(x, w32, bAND2)\n",
        "  \n",
        "# OR Logic Function\n",
        "# w1 = 1, w2 = 1, bOR = -0.5\n",
        "def OR_logicFunction2(x):\n",
        "    w32 = np.array([1, 1])\n",
        "    bOR2 = -0.5\n",
        "    return perceptronModel3_2(x, w32, bOR2)"
      ],
      "metadata": {
        "id": "cFImoMquAuiW"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the Perceptron Model\n",
        "test1 = np.array([0, 0])\n",
        "test2 = np.array([0, 1])\n",
        "test3 = np.array([1, 0])\n",
        "test4 = np.array([1, 1])"
      ],
      "metadata": {
        "id": "atfMoZRKt12g"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test11 = np.array([0, 1])\n",
        "test22 = np.array([1, 1])\n",
        "test33 = np.array([0, 0])\n",
        "test44 = np.array([1, 0])"
      ],
      "metadata": {
        "id": "PzC4uJAs_kB2"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AND_operation():\n",
        "  print(\"Actual output for perceptron\\n\")\n",
        "  print(\"AND({}, {}) = {}\".format(0, 0, AND_logicFunction(test1)))\n",
        "  print(\"AND({}, {}) = {}\".format(0, 1, AND_logicFunction(test2)))\n",
        "  print(\"AND({}, {}) = {}\".format(1, 0, AND_logicFunction(test3)))\n",
        "  print(\"AND({}, {}) = {}\".format(1, 1, AND_logicFunction(test4)))\n",
        "\n",
        "  actual_out = [0,0,0,1]\n",
        "  print(\"\\Target Value\\n\")\n",
        "  print(\"AND({}, {}) = {}\".format(0, 0, actual_out[0]))\n",
        "  print(\"AND({}, {}) = {}\".format(0, 1, actual_out[1]))\n",
        "  print(\"AND({}, {}) = {}\".format(1, 0, actual_out[2]))\n",
        "  print(\"AND({}, {}) = {}\".format(1, 1, actual_out[3]))\n",
        "\n",
        "  print(\"\\nError Values : \\n\")\n",
        "  total_error = 0\n",
        "  for i in range(len(actual)):\n",
        "    error = actual_out[i] - actual[i]\n",
        "    print(error)\n",
        "    total_error += error\n",
        "  print(\"Total Error :- \",total_error)\n",
        "  "
      ],
      "metadata": {
        "id": "4RDn0qVvt6wK"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def OR_operation():\n",
        "  print(\"Actual output for perceptron\\n\")\n",
        "  print(\"OR({}, {}) = {}\".format(0, 0, OR_logicFunction(test1)))\n",
        "  print(\"OR({}, {}) = {}\".format(0, 1, OR_logicFunction(test2)))\n",
        "  print(\"OR({}, {}) = {}\".format(1, 0, OR_logicFunction(test3)))\n",
        "  print(\"OR({}, {}) = {}\".format(1, 1, OR_logicFunction(test4)))\n",
        "\n",
        "  actual_out2 = [0,1,1,1]\n",
        "  print(\"\\Target Value\\n\")\n",
        "  print(\"OR({}, {}) = {}\".format(0, 0, actual_out2[0]))\n",
        "  print(\"OR({}, {}) = {}\".format(0, 1, actual_out2[1]))\n",
        "  print(\"OR({}, {}) = {}\".format(1, 0, actual_out2[2]))\n",
        "  print(\"OR({}, {}) = {}\".format(1, 1, actual_out2[3]))\n",
        "\n",
        "  print(\"\\nError Values : \\n\")\n",
        "  total_error2 = 0\n",
        "  for i in range(len(actual2)):\n",
        "    error2 = actual_out2[i] - actual2[i]\n",
        "    print(error2)\n",
        "    total_error2 += error2\n",
        "  print(\"Total Error :- \",total_error2)"
      ],
      "metadata": {
        "id": "iq9UiS6-t_Zq"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def XOR_operation():\n",
        "  print(\"Actual output for perceptron\\n\")\n",
        "  print(\"XOR({}, {}) = {}\".format(0, 1, XOR_logicFunction(test11)))\n",
        "  print(\"XOR({}, {}) = {}\".format(1, 1, XOR_logicFunction(test22)))\n",
        "  print(\"XOR({}, {}) = {}\".format(0, 0, XOR_logicFunction(test33)))\n",
        "  print(\"XOR({}, {}) = {}\".format(1, 0, XOR_logicFunction(test44)))\n",
        "\n",
        "  actual_out3 = [1,0,0,1]\n",
        "  print(\"\\Target Value\\n\")\n",
        "  print(\"XOR({}, {}) = {}\".format(0, 1, actual_out3[0]))\n",
        "  print(\"XOR({}, {}) = {}\".format(1, 1, actual_out3[1]))\n",
        "  print(\"XOR({}, {}) = {}\".format(0, 0, actual_out3[2]))\n",
        "  print(\"XOR({}, {}) = {}\".format(1, 0, actual_out3[3]))\n",
        "\n",
        "  print(\"\\nError Values : \\n\")\n",
        "  total_error3 = 0\n",
        "  for i in range(len(actual3)):\n",
        "    error3 = actual_out3[i] - actual3[i]\n",
        "    print(error3)\n",
        "    total_error3 += error3\n",
        "  print(\"Total Error :- \",total_error3)"
      ],
      "metadata": {
        "id": "D6b59_ehwBon"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def XOR_operation2():\n",
        "  print(\"Actual output for perceptron\\n\")\n",
        "  print(\"XOR({}, {}) = {}\".format(0, 1, XOR_logicFunction2(test11)))\n",
        "  print(\"XOR({}, {}) = {}\".format(1, 1, XOR_logicFunction2(test22)))\n",
        "  print(\"XOR({}, {}) = {}\".format(0, 0, XOR_logicFunction2(test33)))\n",
        "  print(\"XOR({}, {}) = {}\".format(1, 0, XOR_logicFunction2(test44)))\n",
        "\n",
        "  actual_out32 = [1,0,0,1]\n",
        "  print(\"\\Target Value\\n\")\n",
        "  print(\"XOR({}, {}) = {}\".format(0, 1, actual_out32[0]))\n",
        "  print(\"XOR({}, {}) = {}\".format(1, 1, actual_out32[1]))\n",
        "  print(\"XOR({}, {}) = {}\".format(0, 0, actual_out32[2]))\n",
        "  print(\"XOR({}, {}) = {}\".format(1, 0, actual_out32[3]))\n",
        "\n",
        "  print(\"\\nError Values : \\n\")\n",
        "  total_error32 = 0\n",
        "  for i in range(len(actual3_2)):\n",
        "    error32 = actual_out32[i] - actual3_2[i]\n",
        "    print(error32)\n",
        "    total_error32 += error32\n",
        "  print(\"Total Error :- \",total_error32)"
      ],
      "metadata": {
        "id": "717P35U3CA6k"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choice(num):\n",
        "  if num == 1:\n",
        "    actual.clear()\n",
        "    AND_operation()\n",
        "    main()\n",
        "  elif num == 2:\n",
        "    actual2.clear()\n",
        "    OR_operation()\n",
        "    main()\n",
        "  elif num == 3:\n",
        "    actual3.clear()\n",
        "    XOR_operation()\n",
        "    main()\n",
        "  elif num == 4:\n",
        "    actual3_2.clear()\n",
        "    XOR_operation2()\n",
        "    main()\n",
        "  elif num == 5:\n",
        "    print(\"Exited.\")\n",
        "    return\n",
        "  else:\n",
        "    print(\"Wrong Input\")\n",
        "\n",
        "def main():\n",
        "  print(\"Enter 1-> AND \\t 2 -> OR; \\t 3-> XOR; \\t 4-> XOR2 \\t 5-> EXIT\")\n",
        "  num = int (input(\" \\n Enter your Choice : \"))\n",
        "  choice(num)\n",
        "\n",
        "if __name__ == \"__main__\" :\n",
        "  main()\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzepC1P9x2L7",
        "outputId": "eeb1ec71-468e-4bb8-9a56-54b01d38ff03"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter 1-> AND \t 2 -> OR; \t 3-> XOR; \t 4-> XOR2 \t 5-> EXIT\n",
            " \n",
            " Enter your Choice : 4\n",
            "Actual output for perceptron\n",
            "\n",
            "XOR(0, 1) = 1\n",
            "XOR(1, 1) = 0\n",
            "XOR(0, 0) = 0\n",
            "XOR(1, 0) = 1\n",
            "\\Target Value\n",
            "\n",
            "XOR(0, 1) = 1\n",
            "XOR(1, 1) = 0\n",
            "XOR(0, 0) = 0\n",
            "XOR(1, 0) = 1\n",
            "\n",
            "Error Values : \n",
            "\n",
            "Total Error :-  0\n",
            "Enter 1-> AND \t 2 -> OR; \t 3-> XOR; \t 4-> XOR2 \t 5-> EXIT\n",
            " \n",
            " Enter your Choice : 3\n",
            "Actual output for perceptron\n",
            "\n",
            "XOR(0, 1) = 1\n",
            "XOR(1, 1) = 1\n",
            "XOR(0, 0) = 0\n",
            "XOR(1, 0) = 1\n",
            "\\Target Value\n",
            "\n",
            "XOR(0, 1) = 1\n",
            "XOR(1, 1) = 0\n",
            "XOR(0, 0) = 0\n",
            "XOR(1, 0) = 1\n",
            "\n",
            "Error Values : \n",
            "\n",
            "Total Error :-  0\n",
            "Enter 1-> AND \t 2 -> OR; \t 3-> XOR; \t 4-> XOR2 \t 5-> EXIT\n",
            " \n",
            " Enter your Choice : 5\n",
            "Exited.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ce1K7hzcx2OY"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perceptron is the simplest unit of Neural Network which takes several input and gives us output. Activation function is the step function. \n",
        "b is the threshold value. It acts like linear regression "
      ],
      "metadata": {
        "id": "dtq-4rj76PBp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZGaHjNHjx2T-"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing Python library\n",
        "import numpy as np\n",
        "\n",
        "# define Unit Step Function\n",
        "def unitStep(v):\n",
        "\tif v >= 0:\n",
        "\t\treturn 1\n",
        "\telse:\n",
        "\t\treturn 0\n",
        "\n",
        "# design Perceptron Model\n",
        "def perceptronModel(x, w, b):\n",
        "\tv = np.dot(w, x) + b\n",
        "\ty = unitStep(v)\n",
        "\treturn y\n",
        "\n",
        "# NOT Logic Function\n",
        "# wNOT = -1, bNOT = 0.5\n",
        "def NOT_logicFunction(x):\n",
        "\twNOT = -1\n",
        "\tbNOT = 0.5\n",
        "\treturn perceptronModel(x, wNOT, bNOT)\n",
        "\n",
        "# AND Logic Function\n",
        "# here w1 = wAND1 = 1,\n",
        "# w2 = wAND2 = 1, bAND = -1.5\n",
        "def AND_logicFunction(x):\n",
        "\tw = np.array([1, 1])\n",
        "\tbAND = -1.5\n",
        "\treturn perceptronModel(x, w, bAND)\n",
        "\n",
        "# OR Logic Function\n",
        "# w1 = 1, w2 = 1, bOR = -0.5\n",
        "def OR_logicFunction(x):\n",
        "\tw = np.array([1, 1])\n",
        "\tbOR = -0.5\n",
        "\treturn perceptronModel(x, w, bOR)\n",
        "\n",
        "# XOR Logic Function\n",
        "# with AND, OR and NOT\n",
        "# function calls in sequence\n",
        "def XOR_logicFunction(x):\n",
        "\ty1 = AND_logicFunction(x)\n",
        "\ty2 = OR_logicFunction(x)\n",
        "\ty3 = NOT_logicFunction(y1)\n",
        "\tfinal_x = np.array([y2, y3])\n",
        "\tfinalOutput = AND_logicFunction(final_x)\n",
        "\treturn finalOutput\n",
        "\n",
        "# testing the Perceptron Model\n",
        "test1 = np.array([0, 1])\n",
        "test2 = np.array([1, 1])\n",
        "test3 = np.array([0, 0])\n",
        "test4 = np.array([1, 0])\n",
        "\n",
        "print(\"XOR({}, {}) = {}\".format(0, 1, XOR_logicFunction(test1)))\n",
        "print(\"XOR({}, {}) = {}\".format(1, 1, XOR_logicFunction(test2)))\n",
        "print(\"XOR({}, {}) = {}\".format(0, 0, XOR_logicFunction(test3)))\n",
        "print(\"XOR({}, {}) = {}\".format(1, 0, XOR_logicFunction(test4)))\n"
      ],
      "metadata": {
        "id": "4mR6gRdSx2XC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69428933-a297-4840-8db1-dbff204bb51b"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR(0, 1) = 1\n",
            "XOR(1, 1) = 0\n",
            "XOR(0, 0) = 0\n",
            "XOR(1, 0) = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "34Ob7fIHDBOr"
      },
      "execution_count": 205,
      "outputs": []
    }
  ]
}