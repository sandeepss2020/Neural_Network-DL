{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNfjv2IuxGGJSxP8A9xad5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeepss2020/Neural_Network-DL/blob/main/NNDL_LAB4_ADALINE_ORGATE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the module numpy\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "GkDCH96Iud6r"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWTPDFXjsQ4s",
        "outputId": "44bb0f2e-ac9d-4112-af0d-72633fab93bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orginial Matrix  [[ 1  1]\n",
            " [ 1 -1]\n",
            " [-1  1]\n",
            " [-1 -1]] [ 1  1  1 -1]\n",
            "epoch : 1\n",
            "error = 0.7\n",
            "error = 0.8300000000000001\n",
            "error = 0.913\n",
            "error = -1.0043\n",
            "sum of squared error =  0.7552718725 \n",
            "\n",
            "\n",
            "epoch : 2\n",
            "error = 0.21527000000000007\n",
            "error = 0.751203\n",
            "error = 0.7931233000000001\n",
            "error = -0.83591563\n",
            "sum of squared error =  0.4846116573975468 \n",
            "\n",
            "\n",
            "epoch : 3\n",
            "error = -0.08733519300000014\n",
            "error = 0.6974795122999999\n",
            "error = 0.71725934353\n",
            "error = -0.7353483458829999\n",
            "sum of squared error =  0.3873258154221359 \n",
            "\n",
            "\n",
            "epoch : 4\n",
            "error = -0.2761433552713002\n",
            "error = 0.66111076307843\n",
            "error = 0.669341786894273\n",
            "error = -0.6754034326425002\n",
            "sum of squared error =  0.3543777045566816 \n",
            "\n",
            "\n",
            "epoch : 5\n",
            "error = -0.39388594695143064\n",
            "error = 0.6366406508037212\n",
            "error = 0.6391322538657562\n",
            "error = -0.639748288011841\n",
            "sum of squared error =  0.34455634185180345 \n",
            "\n",
            "\n",
            "epoch : 6\n",
            "error = -0.4672722821341333\n",
            "error = 0.6202637379637779\n",
            "error = 0.6201210085170047\n",
            "error = -0.6185895044697803\n",
            "sum of squared error =  0.34256838263198863 \n",
            "\n",
            "\n",
            "epoch : 7\n",
            "error = -0.5129880225889496\n",
            "error = 0.609354470132218\n",
            "error = 0.608177905680998\n",
            "error = -0.6060646929690626\n",
            "sum of squared error =  0.3429160896530115 \n",
            "\n",
            "\n",
            "epoch : 8\n",
            "error = -0.5414513226904927\n",
            "error = 0.602117521226608\n",
            "error = 0.6006878876653149\n",
            "error = -0.5986709582365854\n",
            "sum of squared error =  0.343736974708772 \n",
            "\n",
            "\n",
            "epoch : 9\n",
            "error = -0.5591635625961957\n",
            "error = 0.597334505708435\n",
            "error = 0.5959984240198419\n",
            "error = -0.5943193199980572\n",
            "sum of squared error =  0.3444754942505746 \n",
            "\n",
            "\n",
            "epoch : 10\n",
            "error = -0.5701797187899702\n",
            "error = 0.5941839002766915\n",
            "error = 0.5930671907203613\n",
            "error = -0.5917666049773423\n",
            "sum of squared error =  0.3450189566356955 \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "features = np.array(\n",
        "\t[\n",
        "\t\t[1, 1],\n",
        "\t\t[1, -1],\n",
        "\t\t[-1, 1],\n",
        "\t\t[-1, -1]\n",
        "\t])\n",
        "\n",
        "labels = np.array([1, 1, 1, -1])\n",
        "print(\"Orginial Matrix \",features, labels)\n",
        "\n",
        "# initialise weights, bias , learning rate, epoch\n",
        "weight = [0.1, 0.1]\n",
        "bias = 0.1\n",
        "learning_rate = 0.1\n",
        "epoch = 10\n",
        "check_num = [10]\n",
        "\n",
        "\n",
        "for i in range(epoch):\n",
        "    # print(check_num)\n",
        "    print(\"epoch :\", i+1)\n",
        "    # variable to check if there is no change in previous weight and present calculated weight\n",
        "    sum_squared_error = 0.0\n",
        "    \n",
        "\n",
        "    # for each of the possible input given in the features\n",
        "    for j in range(features.shape[0]):\n",
        "      actual = labels[j]\n",
        "      x1 = features[j][0]\n",
        "      x2 = features[j][1]\n",
        "      unit = (x1 * weight[0]) + (x2 * weight[1]) + bias\n",
        "      \n",
        "\n",
        "      # error is computed so as to update the weights\n",
        "      error = actual - unit\n",
        "      print(\"error =\", error)\n",
        "\n",
        "      # summation of squared error is calculated\n",
        "      sum_squared_error += error * error\n",
        "      \n",
        "      \n",
        "      \n",
        "\n",
        "      # updation of weights\n",
        "\n",
        "      weight[0] += learning_rate * error * x1\n",
        "      weight[1] += learning_rate * error * x2\n",
        "\n",
        "      # updation of bias\n",
        "      bias += learning_rate * error\n",
        "      \n",
        "\n",
        "\n",
        "    print(\"sum of squared error = \", sum_squared_error/4, \"\\n\\n\")\n",
        "   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO MADALINE"
      ],
      "metadata": {
        "id": "BcibUlTEvgAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.array(\n",
        "\t[\n",
        "\t\t[1, 1],\n",
        "\t\t[1, -1],\n",
        "\t\t[-1, 1],\n",
        "\t\t[-1, -1]\n",
        "\t])\n",
        "\n",
        "labels = np.array([-1, 1, 1, -1])\n",
        "print(\"Orginial Matrix \",features, labels ,\"\\n\")\n",
        "\n",
        "# initialise weights, bias , learning rate, epoch\n",
        "weight = [0.05,0.1,0.2,0.2]\n",
        "bias = [0.3,0.15,0.5]\n",
        "v = [0.5,0.5]\n",
        "\n",
        "learning_rate = 0.5\n",
        "epoch = 5\n",
        "\n",
        "for j in range(epoch):\n",
        "  # print(check_num)\n",
        "  print(\"======================================================================\")\n",
        "  print(\"EPOCH:\", j+1)\n",
        "  # variable to check if there is no change in previous weight and present calculated weight\n",
        "  sum_squared_error = 0.0\n",
        "  avrg_error =[]\n",
        "\n",
        "  for i in range (features.shape[0]):\n",
        "    x1 = features[i][0]\n",
        "    x2 = features[i][1]\n",
        "    Z1 = (x1 * weight[0]) + (x2 * weight[2]) + bias[0]\n",
        "    Z2 = (x1 * weight[1]) + (x2 * weight[3]) + bias[1]\n",
        "    # print(\"x1, x2,  w[0] , w[1] , w[2] , w[3] : \", x1,x2,weight[0],weight[1],weight[2],weight[3])\n",
        "    print(f\"Z1 : {Z1}, Z2 : {Z2}\")\n",
        "\n",
        "    if(Z1>=0):\n",
        "      f_z1 = 1\n",
        "    elif(Z1 <0):\n",
        "      f_z1 = -1\n",
        "    if(Z2>=0):\n",
        "      f_z2 = 1\n",
        "    elif(Z2<0):\n",
        "      f_z2 = -1\n",
        "    # print(\"fz1  and f_z2 : \", f_z1,f_z2)\n",
        "\n",
        "    y = bias[2] + f_z1*v[0] + f_z2* v[1]\n",
        "    # print(y)\n",
        "    \n",
        "    y2 = bias[2] + Z1*v[0] + Z2 *v[1]\n",
        "    T_Error = labels[i] - y2                  \n",
        "    print(\"Total Error is : \" , T_Error)\n",
        "    sum_squared_error += T_Error * T_Error\n",
        "    av=sum_squared_error/4\n",
        "    print(\"SQ error : \" ,av)\n",
        "    avrg_error.append(av)\n",
        "\n",
        "    error1 = labels[i] - Z1\n",
        "    # print(\"error1: \", error1)\n",
        "    error2 = labels[i] - Z2\n",
        "    # print(\"error2: \", error2,\"\\n\\n\")\n",
        "\n",
        "\n",
        "    weight[0] += learning_rate * error1 * x1\n",
        "    weight[1] += learning_rate * error2 * x1\n",
        "    weight[2] += learning_rate * error1 * x2\n",
        "    weight[3] += learning_rate * error2 * x2\n",
        "\n",
        "\n",
        "  # updation of bias\n",
        "    bias[0] += learning_rate * error1\n",
        "    bias[1] += learning_rate * error2\n",
        "\n",
        "  sum_error = 0\n",
        "  # print(avrg_error)\n",
        "  for av_i in (avrg_error):\n",
        "    # print(\"av_i\" , av_i)\n",
        "    sum_error += av_i\n",
        "  s = sum_error/4\n",
        "  print(\"Average Error:\",s,\"\\n\\n\")\n",
        "\n",
        "# print('%.4f' % s)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFyY3tHp1rso",
        "outputId": "9d997a18-8266-4191-d3ec-249a1d356ee2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orginial Matrix  [[ 1  1]\n",
            " [ 1 -1]\n",
            " [-1  1]\n",
            " [-1 -1]] [-1  1  1 -1] \n",
            "\n",
            "======================================================================\n",
            "EPOCH: 1\n",
            "Z1 : 0.55, Z2 : 0.45000000000000007\n",
            "Total Error is :  -2.0\n",
            "SQ error :  1.0\n",
            "Z1 : -0.625, Z2 : -0.675\n",
            "Total Error is :  1.15\n",
            "SQ error :  1.330625\n",
            "Z1 : -1.1375000000000002, Z2 : -1.3125000000000002\n",
            "Total Error is :  1.725\n",
            "SQ error :  2.07453125\n",
            "Z1 : 2.70625, Z2 : 2.5687500000000005\n",
            "Total Error is :  -4.1375\n",
            "SQ error :  6.3542578125\n",
            "Average Error: 2.689853515625 \n",
            "\n",
            "\n",
            "======================================================================\n",
            "EPOCH: 2\n",
            "Z1 : 1.959375, Z2 : 2.0531249999999996\n",
            "Total Error is :  -3.5062499999999996\n",
            "SQ error :  3.0734472656249996\n",
            "Z1 : -2.5890625000000003, Z2 : -2.6296875\n",
            "Total Error is :  3.109375\n",
            "SQ error :  5.490500488281249\n",
            "Z1 : -3.05859375, Z2 : -2.96953125\n",
            "Total Error is :  3.5140625\n",
            "SQ error :  8.577659301757812\n",
            "Z1 : 2.4503906250000007, Z2 : 2.5417968749999993\n",
            "Total Error is :  -3.99609375\n",
            "SQ error :  12.569850616455078\n",
            "Average Error: 7.427864418029785 \n",
            "\n",
            "\n",
            "======================================================================\n",
            "EPOCH: 3\n",
            "Z1 : 3.0693359375, Z2 : 3.0439453125\n",
            "Total Error is :  -4.556640625\n",
            "SQ error :  5.190743446350098\n",
            "Z1 : -2.99462890625, Z2 : -2.9627929687499996\n",
            "Total Error is :  3.4787109375\n",
            "SQ error :  8.216100893020629\n",
            "Z1 : -2.7278808593750004, Z2 : -2.789501953125\n",
            "Total Error is :  3.25869140625\n",
            "SQ error :  10.87086831331253\n",
            "Z1 : 3.1707275390625, Z2 : 3.1272216796875005\n",
            "Total Error is :  -4.648974609375\n",
            "SQ error :  16.27410954296589\n",
            "Average Error: 10.137955548912286 \n",
            "\n",
            "\n",
            "======================================================================\n",
            "EPOCH: 4\n",
            "Z1 : 2.91195068359375, Z2 : 2.91778564453125\n",
            "Total Error is :  -4.4148681640625\n",
            "SQ error :  4.872765226513147\n",
            "Z1 : -2.9079650878906254, Z2 : -2.9358581542968754\n",
            "Total Error is :  3.4219116210937504\n",
            "SQ error :  7.800135012157262\n",
            "Z1 : -3.1313812255859377, Z2 : -3.095681762695313\n",
            "Total Error is :  3.6135314941406254\n",
            "SQ error :  11.064537476943807\n",
            "Z1 : 2.8902847290039064, Z2 : 2.9110519409179685\n",
            "Total Error is :  -4.400668334960938\n",
            "SQ error :  15.906007925525774\n",
            "Average Error: 9.910861410284998 \n",
            "\n",
            "\n",
            "======================================================================\n",
            "EPOCH: 5\n",
            "Z1 : 3.008840179443359, Z2 : 3.0124031066894537\n",
            "Total Error is :  -4.510621643066406\n",
            "SQ error :  5.086426901724771\n",
            "Z1 : -3.061270523071289, Z2 : -3.04163932800293\n",
            "Total Error is :  3.5514549255371097\n",
            "SQ error :  8.23963492375522\n",
            "Z1 : -2.9145071029663083, Z2 : -2.934706306457519\n",
            "Total Error is :  3.4246067047119135\n",
            "SQ error :  11.171617694244668\n",
            "Z1 : 3.0471665382385256, Z2 : 3.038848400115967\n",
            "Total Error is :  -4.543007469177246\n",
            "SQ error :  16.33134691049473\n",
            "Average Error: 10.207256607554847 \n",
            "\n",
            "\n",
            "10.2073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MADALINE FOR MORE EPOCH2"
      ],
      "metadata": {
        "id": "h4Sek1yESkAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.array(\n",
        "\t[\n",
        "\t\t[1, 1],\n",
        "\t\t[1, -1],\n",
        "\t\t[-1, 1],\n",
        "\t\t[-1, -1]\n",
        "\t])\n",
        "\n",
        "labels = np.array([-1, 1, 1, -1])\n",
        "print(\"Orginial Matrix \",features, labels)\n",
        "\n",
        "# initialise weights, bias , learning rate, epoch\n",
        "weight = [0.05,0.1,0.2,0.2]\n",
        "bias = [0.3,0.15,0.5]\n",
        "v = [0.5,0.5]\n",
        "\n",
        "learning_rate = 0.5\n",
        "epoch = 5\n",
        "\n",
        "\n",
        "for i in range (features.shape[0]):\n",
        "  x1 = features[i][0]\n",
        "  x2 = features[i][1]\n",
        "  Z1 = (x1 * weight[0]) + (x2 * weight[2]) + bias[0]\n",
        "  Z2 = (x1 * weight[1]) + (x2 * weight[3]) + bias[1]\n",
        "  print(\"x1, x2,  w[0] , w[1] , w[2] , w[3] : \", x1,x2,weight[0],weight[1],weight[2],weight[3])\n",
        "  print(Z1,Z2)\n",
        "\n",
        "  if(Z1>=0):\n",
        "    f_z1 = 1\n",
        "  elif(Z1 <0):\n",
        "    f_z1 = -1\n",
        "  if(Z2>=0):\n",
        "    f_z2 = 1\n",
        "  elif(Z2<0):\n",
        "    f_z2 = -1\n",
        "  print(\"fz1  and f_z2 : \", f_z1,f_z2)\n",
        "\n",
        "  y = bias[2] + f_z1*v[0] + f_z2* v[1]\n",
        "  print(y)\n",
        "        \n",
        "  T_Error = labels[i] - y                   #need to change the value of label [0] later\n",
        "  print(\"Error is : \" , T_Error)\n",
        "\n",
        "  error1 = labels[i] - Z1\n",
        "  print(\"error1: \", error1)\n",
        "  error2 = labels[i] - Z2\n",
        "  print(\"error2: \", error2,\"\\n\\n\")\n",
        "\n",
        "\n",
        "  weight[0] += learning_rate * error1 * x1\n",
        "  weight[1] += learning_rate * error2 * x1\n",
        "  weight[2] += learning_rate * error1 * x2\n",
        "  weight[3] += learning_rate * error2 * x2\n",
        "\n",
        "\n",
        " # updation of bias\n",
        "  bias[0] += learning_rate * error1\n",
        "  bias[1] += learning_rate * error2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TP83-odJ9TGV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d679112-6753-4b64-c979-7c3ab36778ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orginial Matrix  [[ 1  1]\n",
            " [ 1 -1]\n",
            " [-1  1]\n",
            " [-1 -1]] [-1  1  1 -1]\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] :  1 1 0.05 0.1 0.2 0.2\n",
            "0.55 0.45000000000000007\n",
            "fz1  and f_z2 :  1 1\n",
            "1.5\n",
            "Error is :  -2.5\n",
            "error1:  -1.55\n",
            "error2:  -1.4500000000000002 \n",
            "\n",
            "\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] :  1 -1 -0.725 -0.6250000000000001 -0.575 -0.5250000000000001\n",
            "-0.625 -0.675\n",
            "fz1  and f_z2 :  -1 -1\n",
            "-0.5\n",
            "Error is :  1.5\n",
            "error1:  1.625\n",
            "error2:  1.675 \n",
            "\n",
            "\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] :  -1 1 0.08750000000000002 0.2124999999999999 -1.3875 -1.3625000000000003\n",
            "-1.1375000000000002 -1.3125000000000002\n",
            "fz1  and f_z2 :  -1 -1\n",
            "-0.5\n",
            "Error is :  1.5\n",
            "error1:  2.1375\n",
            "error2:  2.3125 \n",
            "\n",
            "\n",
            "x1, x2,  w[0] , w[1] , w[2] , w[3] :  -1 -1 -0.9812500000000001 -0.9437500000000001 -0.31874999999999987 -0.20625000000000027\n",
            "2.70625 2.5687500000000005\n",
            "fz1  and f_z2 :  1 1\n",
            "1.5\n",
            "Error is :  -2.5\n",
            "error1:  -3.70625\n",
            "error2:  -3.5687500000000005 \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RGSO5m33HhAm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}